{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TKD_Eval v17.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "_Ay3--Y4uMgG",
    "wzmz5ZxAMLjZ",
    "H64yY_BJMX2h",
    "iSnMmPE_kiK3"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X38L6tanrnrB"
   },
   "source": [
    "# Evaluating Taekwondo Moves\n",
    "System to recognize and evaluate video of performed taekwondo moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voAnieeAs1sm"
   },
   "source": [
    "##Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFffW6If8QSV"
   },
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import exists, join, basename, splitext\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "from datetime import datetime"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hKb97qtlJCld"
   },
   "source": [
    "!pip install -U scikit-learn"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nZ3Ud9zLgOoQ"
   },
   "source": [
    "def show_local_mp4_video(file_name, width=640, height=480):\n",
    "    import io\n",
    "    import base64\n",
    "    from IPython.display import HTML\n",
    "    video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
    "    return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
    "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
    "                      </video>'''.format(width, height, video_encoded.decode('ascii')))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xa7Uzv5eDNoc"
   },
   "source": [
    "def zip_folder(zip_folder_name, direc):\n",
    "    \"\"\"\n",
    "    Zips up the given folder\n",
    "    :param zip_folder_name: the name for the zip folder, ex. `smedaram.zip`\n",
    "    :param direc: the directory for which all the files inside are zipped\n",
    "    \"\"\"\n",
    "    !zip -q -r \"$zip_folder_name\" \"$direc\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0s_A1_9H0zCk"
   },
   "source": [
    "def unzip_folder(zip_folder_name, direc='/content'):\n",
    "    \"\"\"\n",
    "    Unzips the given folder\n",
    "    :param zip_folder_name: Unzips the given .zip file\n",
    "    :param direc: the directory for where the .zip file is stored, assumed to be within /content, which is the base directory in Google Colab\n",
    "    \"\"\"\n",
    "    !unzip \"$zip_folder_name\" -d \"$direc\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WAqUyekQ8q1c"
   },
   "source": [
    "def remove_folder(folder_name):\n",
    "    !rm -r \"$folder_name\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7XyX3J_JOGM-"
   },
   "source": [
    "def get_time():\n",
    "    return f'{datetime.now()}'.replace(' ', '_').replace(':', '-')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUi8c4RRuUbh",
    "outputId": "addf497a-5adb-48a8-edee-9665b5c88954"
   },
   "source": [
    "#Base Directory\n",
    "lu = 'drive/MyDrive/Senior_Research'\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2m1NUtAhEJpT"
   },
   "source": [
    "#abbreviations for each of the 10 moves\n",
    "abbreviations = {\n",
    "    \"High block\": \"hb\",\n",
    "    \"Middle block (in-to-out)\": \"mbio\",\n",
    "    \"Middle block (out-to-in)\": \"mboi\",\n",
    "    \"Knife hand block\": \"khb\",\n",
    "    \"Low block\": \"lb\",\n",
    "    \"Punch (middle-level)\": \"p\",\n",
    "    \"High punch (face-level)\": \"hp\",\n",
    "    \"Front kick\": \"fk\",\n",
    "    \"Round kick\": \"rk\",\n",
    "    \"Side kick\": \"sk\"\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuQOIhMI8hv4"
   },
   "source": [
    "## Skeleton Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzmz5ZxAMLjZ"
   },
   "source": [
    "Get Existing Custom Datasets as of February 23, 2021"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2qOMoSQz1AWy"
   },
   "source": [
    "unzip_folder(os.path.join(lu,'VideoPose3D-2021-02-23.zip'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H64yY_BJMX2h"
   },
   "source": [
    "###Create Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GsJSIwCD9hB3"
   },
   "source": [
    "# git_repo_url = 'https://github.com/facebookresearch/VideoPose3D.git'\n",
    "# project_name = splitext(basename(git_repo_url))[0]\n",
    "# if not exists(project_name):\n",
    "#   # clone and install dependencies\n",
    "#    !git clone -q --depth 1 $git_repo_url"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TneKBqDy55Jk"
   },
   "source": [
    "!python3 -m pip install --upgrade pip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b-i4hmGYk1dL"
   },
   "source": [
    "# install dependencies: \n",
    "!pip install pyyaml==5.1\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "# opencv is pre-installed on colab"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "exqzM_yMVXxT"
   },
   "source": [
    "# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "import torch\n",
    "assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8 if Colab changes its default version\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
    "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZyAvNCJMmvFF"
   },
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6V1MtSBtzad"
   },
   "source": [
    "*Make sure to upload the pretrained model to the checkpoint folder if you took VideoPose3D straight from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qiA-N5BsFYYN"
   },
   "source": [
    "def create_train_custom_dataset(videos, side, move, slow):\n",
    "    \"\"\"\n",
    "    Creates a custom dataset within VideoPose3D for the given move on the given side given training dataset\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param side: the side for which to create a custom dataset, ex. `Left`\n",
    "    :param move: the move for which to create a custom dataset, ex. `High block`\n",
    "    :param slow: boolean for whether or not the video should be slowed down before its processed frame by frame; currently obsolete, since discovered the slowing down the video does little to change a blurry frame in and of itself\n",
    "    :return: if downloads are successful, returns the prefix of the move (ex. `mboi_l`) and the custom dataset name (ex. `mboi_l_dataset`); if not, returns None\n",
    "    \"\"\"\n",
    "    prefix = download_all_videos(videos, side, move, slow)\n",
    "    if prefix != None:\n",
    "        # create an output folder for the 2D estimates\n",
    "        twod_outputs_folder = f'{prefix}_2d_outputs'\n",
    "        if not os.path.exists(twod_outputs_folder):\n",
    "            os.makedirs(twod_outputs_folder)\n",
    "        !cd VideoPose3D/inference && python3 infer_video_d2.py --cfg COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml --output-dir ../../\"$twod_outputs_folder\"  --image-ext mp4 ../../\"$prefix\"/\n",
    "        !cd VideoPose3D/data/ && python3 prepare_data_2d_custom.py -i ../../\"$twod_outputs_folder\" -o \"$prefix\"_dataset\n",
    "        return prefix, f'{prefix}_dataset'\n",
    "    return None, None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MgJ9ihNPnGH9"
   },
   "source": [
    "def create_train_custom_dataset_for_given_moves(moves):\n",
    "    \"\"\"\n",
    "    Creates a custom dataset for each side of all moves given\n",
    "    :param moves: list of strings for all the moves for which to generate custom datasets for, ex. `['High block', 'Low block']\n",
    "    \"\"\"\n",
    "    # pdts = {}\n",
    "    for m in moves:\n",
    "        prefix, dts = create_train_custom_dataset(videos, 'Left', m, slow=False)\n",
    "        # pdts[prefix] = dts\n",
    "        prefix, dts = create_train_custom_dataset(videos, 'Right', m, slow=False)\n",
    "        # pdts[prefix] = dts\n",
    "    folder_name = f\"{lu}/VideoPose3D-{get_t()}.zip\"\n",
    "    zip_folder(folder_name, \"VideoPose3D/\")\n",
    "    # pickle.dump(pdts, open( \"pdts.p\", \"wb\" )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TLuMRpbsTKLl"
   },
   "source": [
    "def create_custom_dataset(leadup, ip_folder, slow):\n",
    "    \"\"\"\n",
    "    Creates custom dataset for all the files inside ip_folder\n",
    "    :param leadup: the path to ip_folder\n",
    "    :param ip_folder: the name of the folder which contains all video files for which the custom dataset should be made\n",
    "    :param slow: boolean for whether or not the video should be slowed down before its processed frame by frame; currently obsolete, since discovered the slowing down the video does little to change a blurry frame in and of itself\n",
    "    :return: the name of the output folder (where the .npy and .mp4 files will be stored) and the name of the custom dataset\n",
    "    \"\"\"\n",
    "    p = os.path.join(leadup, ip_folder)\n",
    "    if slow == True:\n",
    "        oup_folder = f'{ip_folder}_slow'\n",
    "        new_p = os.path.join(leadup, oup_folder)\n",
    "        if not os.path.exists(new_p):\n",
    "          os.makedirs(new_p)\n",
    "\n",
    "        for f in os.listdir(p):\n",
    "            # print(f)\n",
    "            vidfn, ext = os.path.splitext(f)\n",
    "            slow_down_video(os.path.join(p, f), os.path.join(new_p, f), speed=2.0)\n",
    "    else:\n",
    "        new_p = p\n",
    "        oup_folder = ip_folder\n",
    "\n",
    "    twod_outputs_folder = f'{oup_folder}_2d_outputs'\n",
    "    if not os.path.exists(twod_outputs_folder):\n",
    "        os.makedirs(twod_outputs_folder)\n",
    "    !cd VideoPose3D/inference && python3 infer_video_d2.py --cfg COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml --output-dir ../../\"$twod_outputs_folder\"  --image-ext mp4 ../../\"$new_p\"/\n",
    "    !cd VideoPose3D/data/ && python3 prepare_data_2d_custom.py -i ../../\"$twod_outputs_folder\" -o \"$oup_folder\"_dataset\n",
    "    return oup_folder, f'{oup_folder}_dataset'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ay3--Y4uMgG"
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L7k_dH9NB8rO"
   },
   "source": [
    "import pandas as pd\n",
    "import io"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zU5b6dlRwUQk"
   },
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient.http import MediaIoBaseDownload"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zRenQEM0ATtz"
   },
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xIUfoMPV_TN2"
   },
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from googleapiclient.discovery import build\n",
    "drive_service = build('drive', 'v3')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-BwIPF4uubsb"
   },
   "source": [
    "df_train = pd.read_excel(f'{lu}/Evaluating_TKD_Video_Submission_Responses_v2.xlsx', index_col=None, na_values=['NA'], usecols=['Timestamp', 'Athlete Name', 'Level Ability', 'Move', 'Side', 'Iteration #', \"View\", \"Upload video here\"])\n",
    "df_train.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FifUcbNTc4kT"
   },
   "source": [
    "df_full = pd.read_excel(f'{lu}/Evaluating_TKD_Video_Submission_Responses_v4.xlsx', index_col=None, na_values=['NA'], usecols=['Timestamp', 'Athlete Name', 'Level Ability', 'Move', 'Side', 'Iteration #', \"View\", \"Upload video here\", \"Ideal\"])\n",
    "df_full.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XEkmcz_RBonV"
   },
   "source": [
    "df_test = pd.read_excel(f'{lu}/Evaluating_TKD_Video_Submission_Responses_v4_Test.xlsx', index_col=None, na_values=['NA'], usecols=['Timestamp', 'Athlete Name', 'Level Ability', 'Move', 'Side', 'Iteration #', \"View\", \"Upload video here\"])\n",
    "df_test.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tAi0ojuM_CEf"
   },
   "source": [
    "def get_file_ids(df):\n",
    "    \"\"\"\n",
    "    Gets the file ids from the df object\n",
    "    :param df: the pandas dataframe object\n",
    "    :return: the dict of dict of dicts objects that store the file ids, progressively organized by view, side, and move\n",
    "    \"\"\"\n",
    "    videos = {'Front': {'Left': {}, 'Right': {}},\n",
    "              'Diagonal': {'Left': {}, 'Right': {}}}  # view --> side --> moves --> ids\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        view = videos[row['View']]\n",
    "        if row['Move'] in view[row['Side']]:\n",
    "            side = view[row['Side']]\n",
    "            side[row['Move']].add(row['Upload video here'][row['Upload video here'].find('id') + 3:])\n",
    "        else:\n",
    "            side = view[row['Side']]\n",
    "            side[row['Move']] = set()\n",
    "            url = row['Upload video here']\n",
    "            # print(url)\n",
    "            i = url.find('id') + 3\n",
    "            # print(i)\n",
    "            side[row['Move']].add(url[i:])\n",
    "    return videos"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ADTL6DWbbc4J"
   },
   "source": [
    "def get_ideal_file_ids(df):\n",
    "    \"\"\"\n",
    "    Gets the ideal file ids (the videos for the \"ideal\" execution) from the df object\n",
    "    :param df: the pandas dataframe object\n",
    "    :return: the dict of dict of dicts objects that store the file ids, progressively organized by view, side, and move\n",
    "    \"\"\"\n",
    "\n",
    "    move2ideal = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        ideal = row['Ideal']\n",
    "        if ideal == \"Yes\":\n",
    "            prefix = f\"{abbreviations[row['Move']]}_{row['Side'][0].lower()}\"\n",
    "            move2ideal[prefix] = row['Upload video here'][row['Upload video here'].find('id') + 3:]\n",
    "    return move2ideal"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uIsTd6H9DbfK"
   },
   "source": [
    "def print_videos(videos):\n",
    "    for view in videos:\n",
    "        print(f'{view}')\n",
    "        for side in videos[view]:\n",
    "            print(f'\\t{side}')\n",
    "            moves = videos[view][side]\n",
    "            for m in moves:\n",
    "                print(f'\\t\\t{m} ({len(moves[m])}): {moves[m]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RcjOB7ikBXVk"
   },
   "source": [
    "train_videos = get_file_ids(df_train)\n",
    "print_videos(train_videos)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZtLcDpzwCENm"
   },
   "source": [
    "test_videos = get_file_ids(df_test)\n",
    "print_videos(test_videos)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VPDW-e0s6uOA"
   },
   "source": [
    "def slow_down_video(input_name, output_name, speed=3.0):\n",
    "    \"\"\"\n",
    "    Slows down the given video by the appropriate speed\n",
    "    :param input_name: the filename for the original video\n",
    "    :param output_name: the filename for the output video\n",
    "    :param speed: the speed by which the video should be slowed down, ex. x3\n",
    "    \"\"\"\n",
    "\n",
    "    !ffmpeg -i \"$input_name\" -filter:v \"setpts=$speed*PTS\" \"$output_name\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ikpxghyph1uX"
   },
   "source": [
    "def naming_convention(c, prefix, view, count):\n",
    "    \"\"\"\n",
    "    How the new 3D reconstruction video should be named\n",
    "    :param c: the format by which the video should be named, either 'regular' for the train/test dataset or 'ideal' for the ideal executions\n",
    "    :param prefix: in train/test sets, the prefix for the given video, ex. 'mbio_l'\n",
    "    :param view: from which view the video was taken, 'Front' or 'Diagonal'\n",
    "    :param count: a unique identifier for this video, usually a count within the prefix and view categories\n",
    "    :return: how the given video should be named\n",
    "    \"\"\"\n",
    "    if c == 'regular':\n",
    "        filename = prefix + f'{view[0].lower()}_{count}.mp4'\n",
    "    else:\n",
    "        filename = prefix + '_ideal.mp4'\n",
    "    return filename"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HQwgCVJhfs2T"
   },
   "source": [
    "def download_video_helper(file_id, dir, prefix, view, count, convention):\n",
    "    \"\"\"\n",
    "    Downloads the given video\n",
    "    :param file_id: the file id for the video (stored in GDrive)\n",
    "    :param dir: the directory where the downloaded video should be outputted\n",
    "    :param prefix: the category this video belongs to, ex. 'mbio_l', for the naming convention\n",
    "    :param view: the view from which this video was taken, ex. 'Diagonal', for the naming convention\n",
    "    :param count: a unique identifier for this video, usually a count within the prefix and view categories\n",
    "    :param convention: the format by which the video should be named, either 'regular' for the train/test dataset or 'ideal' for the ideal executions\n",
    "    \"\"\"\n",
    "\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        # print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "    fh.seek(0)\n",
    "\n",
    "    filename = naming_convention(convention, prefix, view, count)\n",
    "\n",
    "    with open(os.path.join(dir, filename), 'wb') as f:\n",
    "        f.write(fh.read())\n",
    "        f.close()\n",
    "\n",
    "def download_all_videos_helper(videos, dir, prefix, view, side, move):\n",
    "    \"\"\"\n",
    "    Downloads all videos for this move, side, and view\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param dir: the directory where the downloaded videos should be stored\n",
    "    :param prefix: in train/test sets, the prefix for the given video, ex. 'mbio_l'\n",
    "    :param view: from which view the video was taken, 'Front' or 'Diagonal'\n",
    "    :param side: the side for which to download videos, ex. `Left`\n",
    "    :param move: the move for which to download videos, ex. `High block`\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for file_id in videos[view][side][move]:\n",
    "        # print(file_id)\n",
    "        download_video_helper(file_id, dir, prefix, view, count, 'regular')\n",
    "        count += 1\n",
    "    print(f'Downloaded all {view}-view videos of {side}-side {move} moves')\n",
    "\n",
    "def download_all_video_views(dir, prefix, videos, side, move):\n",
    "    \"\"\"\n",
    "    Downloads all videos for this move and side on all views\n",
    "    :param dir: the directory where the downloaded videos should be stored\n",
    "    :param prefix: in train/test sets, the prefix for the given video, ex. 'mbio_l'\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param side: the side for which to download videos, ex. `Left`\n",
    "    :param move: the move for which to download videos, ex. `High block`\n",
    "    \"\"\"\n",
    "    if move in videos['Front'][side]:\n",
    "        download_all_videos_helper(videos, dir, prefix, 'Front', side, move)\n",
    "    if move in videos['Diagonal'][side]:\n",
    "        download_all_videos_helper(videos, dir, prefix, 'Diagonal', side, move)\n",
    "\n",
    "def download_all_videos(leadup, videos, side, move, slow, dts_id=None):\n",
    "    \"\"\"\n",
    "    Downloads all videos in `videos`\n",
    "    :param leadup: the leadup to the directory where all the videos should be stored\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param side: the side for which to download videos, ex. `Left`\n",
    "    :param move: the move for which to download videos, ex. `High block`\n",
    "    :param slow: whether to slow down the given video, often defaults to false\n",
    "    :param dts_id: a special identifier added to the end of directory name, ex. `test`\n",
    "    :return: if successful, the prefix, if not, None\n",
    "    \"\"\"\n",
    "    print('f')\n",
    "    if slow:\n",
    "        if dts_id == None:\n",
    "            dir = os.path.join(leadup, f'{abbreviations[move]}_{side[0].lower()}_init_')\n",
    "            print(dir)\n",
    "            if not os.path.exists(dir):  # make the initial videos folder\n",
    "                os.makedirs(dir)\n",
    "    else:\n",
    "        if dts_id == None:\n",
    "            dir = os.path.join(leadup, f'{abbreviations[move]}_{side[0].lower()}')\n",
    "        else:\n",
    "            dir = os.path.join(leadup, f'{abbreviations[move]}_{side[0].lower()}_{dts_id}')\n",
    "\n",
    "    if dts_id == None:\n",
    "        fdir = os.path.join(leadup, f'{abbreviations[move]}_{side[0].lower()}')\n",
    "    else:\n",
    "        fdir = os.path.join(leadup, f'{abbreviations[move]}_{side[0].lower()}_{dts_id}')\n",
    "\n",
    "    if not os.path.exists(fdir):\n",
    "        os.makedirs(fdir)  # make the final videos folder\n",
    "        prefix = f'{abbreviations[move]}_{side[0].lower()}'\n",
    "        print(prefix)\n",
    "\n",
    "        download_all_video_views(dir, prefix, videos, side, move)\n",
    "\n",
    "        if slow:\n",
    "            for f in os.listdir(dir):\n",
    "                vidfn, ext = os.path.splitext(f)\n",
    "                slow_down_video(os.path.join(dir, f), os.path.join(fdir, f'{vidfn}.mp4'))\n",
    "\n",
    "        return prefix\n",
    "    else:\n",
    "        return None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPQyNKJs0SG0"
   },
   "source": [
    "## Pose Classification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u-dvUe6K8yTY"
   },
   "source": [
    "# moves = [\"High block\", \"Middle block (in-to-out)\", \"Middle block (out-to-in)\", \"Knife hand block\", \"Low block\", \"Punch (middle-level)\", \"High punch (face-level)\", \"Front kick\", \"Round kick\", \"Side kick\"]\n",
    "# moves = [\"High block\", \"Middle block (in-to-out)\", \"Middle block (out-to-in)\", \"Knife hand block\", \"Low block\", \"Punch (middle-level)\", \"High punch (face-level)\"]\n",
    "# moves = [\"Front kick\", \"Round kick\", \"Side kick\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7T0zHOUmUwGG"
   },
   "source": [
    "def reconstruct_video_helper(path, threed_outputs_folder, custom_dataset, video_fn):\n",
    "    \"\"\"\n",
    "    Runs the command to reconstruct the given video into its 3D representation; creates a .npy (frame by frame position of joints) file and .mp4 video\n",
    "    :param path: the path to the video\n",
    "    :param threed_outputs_folder: the (path to the) folder where the output is stored\n",
    "    :param custom_dataset: the name of the custom dataset which stores the 2D results from Detectron\n",
    "    :param video_fn: the name of the video to be reconstructed\n",
    "    \"\"\"\n",
    "\n",
    "    p = os.path.join(path, video_fn)\n",
    "    print(p)\n",
    "    # print(f'cd VideoPose3D/ && python run.py -d custom -k {custom_dataset} -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_detectron_coco.bin --render --viz-subject {video_fn}.mp4 --viz-action custom --viz-camera 0 --viz-video ../{p}.mp4 --viz-output ../{threed_outputs_folder}/{video_fn}_si.mp4 --viz-export ../{threed_outputs_folder}/{video_fn}_si --viz-size 6')\n",
    "    !cd VideoPose3D/ && python run.py -d custom -k \"$custom_dataset\" -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_detectron_coco.bin --render --viz-subject \"$video_fn\".mp4 --viz-action custom --viz-camera 0 --viz-video ../\"$p\".mp4 --viz-output ../\"$threed_outputs_folder\"/\"$video_fn\"_si.mp4 --viz-export ../\"$threed_outputs_folder\"/\"$video_fn\"_si --viz-size 6\n",
    "\n",
    "def reconstruct_videos(leadup, prefix, dts, folder=None):\n",
    "    \"\"\"\n",
    "    Runs `reconstruct_video_helper` for all the videos in the given folder\n",
    "    :param leadup: the path to the folder\n",
    "    :param prefix: if the videos are the training set, prefix is the name of the folder\n",
    "    :param dts: the name of the custom dataset\n",
    "    :param folder: if the videos are not part of the training set, this is the name of the folder\n",
    "    :return: the name of the output folder\n",
    "    \"\"\"\n",
    "\n",
    "    # path = f'../{prefix}/'\n",
    "    # print(f'Dataset name: {dts}')\n",
    "    if folder is None:\n",
    "        p = os.path.join(leadup, prefix)\n",
    "        threed_outputs_folder = os.path.join(leadup, f'{prefix}_3d_outputs')\n",
    "    else:\n",
    "        p = os.path.join(leadup, folder)\n",
    "        threed_outputs_folder = os.path.join(leadup, f'{folder}_3d_outputs')\n",
    "\n",
    "    if not os.path.exists(threed_outputs_folder):\n",
    "        os.makedirs(threed_outputs_folder)\n",
    "\n",
    "    for f in os.listdir(p):\n",
    "        print(f)\n",
    "        vidfn, ext = os.path.splitext(f)\n",
    "        reconstruct_video_helper(p, threed_outputs_folder, dts, vidfn)\n",
    "    return threed_outputs_folder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSnMmPE_kiK3"
   },
   "source": [
    "###Generate Vocabulary Poses with K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JctIQCO0jFTa"
   },
   "source": [
    "hand_techniques = [\"High block\", \"Middle block (in-to-out)\", \"Middle block (out-to-in)\", \"Knife hand block\", \"Low block\", \"Punch (middle-level)\", \"High punch (face-level)\"]\n",
    "kicking_techniques = [\"Front kick\", \"Round kick\", \"Side kick\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I1a98Qsq3XjR"
   },
   "source": [
    "from sklearn.cluster import KMeans"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SGpX-sfIkhgc"
   },
   "source": [
    "h36m_num_joints = 17\n",
    "h36m_joints = {\n",
    "    0: [7,8,9],\n",
    "    1: [14,8,11],\n",
    "    2: [8,14,15],\n",
    "    3: [14,15,16],\n",
    "    4: [8,11,12],\n",
    "    5: [11,12,13],\n",
    "    6: [7,1,2],\n",
    "    7: [1,2,3],\n",
    "    8: [7,4,5],\n",
    "    9: [4,5,6],\n",
    "    10: [16,7,13],\n",
    "    11: [3,7,6],\n",
    "    12: [8,7,16],\n",
    "    13: [8,7,13]\n",
    "}\n",
    "def calc_angle(angle_jgroup, coordinates):\n",
    "    \"\"\"\n",
    "    Calculates all the angles as specified by angle_jgroup and coordinates\n",
    "    :param angle_jgroup: a dictionary which references which 3 joints make which angle\n",
    "    :param coordinates: a numpy array which represents all the x,y,z coordinates of the joints\n",
    "    :return: a numpy array of angles between joints in radians\n",
    "    \"\"\"\n",
    "    angles = np.array([])\n",
    "    for i in angle_jgroup:\n",
    "        s,c,e = angle_jgroup[i]\n",
    "        s_hat = coordinates[s] - coordinates[c]\n",
    "        c_hat = coordinates[c] - coordinates[c]\n",
    "        e_hat = coordinates[e] - coordinates[c]\n",
    "\n",
    "        dot_product = s_hat@e_hat\n",
    "        alpha = math.acos((dot_product)/(np.linalg.norm(s_hat)*np.linalg.norm(e_hat)))\n",
    "\n",
    "        angles = np.append(angles, alpha)\n",
    "    return angles\n",
    "\n",
    "def get_angles(data):\n",
    "    \"\"\"\n",
    "    Calculates angles between joints for each frame in a given video, represented as `data`\n",
    "    :param data: the .npy file containing a numpy array of coordinates of joints for each frame in video\n",
    "    :return: all the angles, a series of numpy arrays (each array is one frame)\n",
    "    \"\"\"\n",
    "    ang = np.empty((len(data), len(h36m_joints)))\n",
    "    for i, frame in enumerate(data):\n",
    "        f_ang = ang = calc_angle(h36m_joints, frame)\n",
    "        ang[i] = f_ang\n",
    "    return ang"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xy6dU4Zv3B6r"
   },
   "source": [
    "def get_cluster_centroids(k, ips):\n",
    "    \"\"\"\n",
    "    Returns `k` cluster centroids for videos represented by `ips`, a bunch of NumPy archives\n",
    "    :param k: number of clusters\n",
    "    :param ips: all the input files, a list of .npy files\n",
    "    :return: scikit-learn's kmeans object, which contains .cluster_centers_\n",
    "    \"\"\"\n",
    "    X = get_angles(np.load(ips[0]))\n",
    "    i = 1\n",
    "    while i < len(ips):\n",
    "        data = get_angles(np.load(ips[i]))\n",
    "        X = np.concatenate((X, data))\n",
    "        i += 1\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "\n",
    "    # print(kmeans.labels_)\n",
    "    # cc = kmeans.cluster_centers_\n",
    "    # print(cc)\n",
    "    return kmeans"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sPO3lOxBL73l"
   },
   "source": [
    "def get_ips(leadup, prefix):\n",
    "    \"\"\"\n",
    "    Gets all the input filenames, as in all the 3D reconstruction .npy files within the folder\n",
    "    :param leadup: the path to the folder\n",
    "    :param prefix: the name of the folder (most often the prefix, if its the training set)\n",
    "    :return: the list of all input filenames (including paths)\n",
    "    \"\"\"\n",
    "    threed_outputs_folder = os.path.join(leadup, f'{prefix}_3d_outputs')\n",
    "    ips = []\n",
    "    for f in os.listdir(threed_outputs_folder):\n",
    "        vidfn, ext = os.path.splitext(f)\n",
    "        # print(ext)\n",
    "        if ext == '.npy':\n",
    "            ips.append(os.path.join(threed_outputs_folder, f))\n",
    "    print(ips)\n",
    "    return ips"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wc4pgLeqjkvH"
   },
   "source": [
    "def get_all_cluster_centroids_helper(leadup, videos, k, side, move, ks, dl=False):\n",
    "    \"\"\"\n",
    "    For a given move and side, gets all the vocabulary poses (for training)\n",
    "    :param leadup: the path to the videos\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param k: the number of vocabulary poses for each move\n",
    "    :param side: the side for which to get vocabulary poses, ex. `Left`\n",
    "    :param move: the move for which to get vocabulary poses, ex. `High block`\n",
    "    :param ks: the dictionary which maps prefix to scikit-learn's kmeans object that contains the vocabulary poses as cluster centroids\n",
    "    :param dl: if a download is necessary, defaults to false since oftentimes the videos have already been downloaded in the current runtime\n",
    "    :return: the kmeans object containing the vocabulary poses as cluster centroids\n",
    "    \"\"\"\n",
    "\n",
    "    if dl == True:\n",
    "        prefix = download_all_videos(leadup, videos, side, move, slow=False)\n",
    "        dts = f'{prefix}_dataset'\n",
    "        threed_outputs_folder = reconstruct_videos(leadup, prefix, dts)\n",
    "    else:\n",
    "        prefix = f'{abbreviations[move]}_{side[0].lower()}'\n",
    "    ips = get_ips(leadup, prefix)\n",
    "    kmeans = get_cluster_centroids(k, ips)\n",
    "    ks[prefix] = kmeans\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "def get_all_cluster_centroids(leadup, videos, k, moves, ks, ks_path, dl=False):\n",
    "    \"\"\"\n",
    "    For all the moves given, gets vocabulary poses\n",
    "    :param leadup: the path to the videos\n",
    "    :param videos: the dict of dict of dict objects that contains all the fileids of the videos organized progressively by view, side, and move\n",
    "    :param k: the number of vocabulary poses for each move\n",
    "    :param moves: list of all the moves for which to get vocabulary poses\n",
    "    :param ks: the dictionary which maps prefix to scikit-learn's kmeans object that contains the vocabulary poses as cluster centroids\n",
    "    :param ks_path: the path for where to dump the `ks` object\n",
    "    :param dl: if a download is necessary, defaults to false since oftentimes the videos have already been downloaded in the current runtime\n",
    "    \"\"\"\n",
    "\n",
    "    for m in moves:\n",
    "        print(f'{abbreviations[m]}_r')\n",
    "        get_all_cluster_centroids_helper(leadup, videos, k, \"Right\", m, ks, dl=dl)\n",
    "        pickle.dump(ks, open(ks_path, \"wb\"))\n",
    "        print(f'{abbreviations[m]}_l')\n",
    "        get_all_cluster_centroids_helper(leadup, videos, k, \"Left\", m, ks, dl=dl)\n",
    "        pickle.dump(ks, open(ks_path, \"wb\"))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UxdWvL3KSwDu"
   },
   "source": [
    "# unzip_folder(os.path.join(lu, 'TrainSet_NPYs&MP4s.zip'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_pig_SqUkqlw"
   },
   "source": [
    "# ks = {}\n",
    "hand_vp = 10\n",
    "kick_vp = 12\n",
    "# ks_path = os.path.join(lu, f'ks-h{hand_vp}k{kick_vp}.p')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IM65BMbc__xK"
   },
   "source": [
    "# get_all_cluster_centroids('', train_videos, hand_vp, hand_techniques, ks, ks_path)\n",
    "# get_all_cluster_centroids('', train_videos, kick_vp, kicking_techniques, ks, ks_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ev2IZn2hG3jn"
   },
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7e_RfK1TF5kZ"
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UqyH30_sFZAR"
   },
   "source": [
    "def get_data(path_to_ks, suffix, new_identifiers=False):\n",
    "    \"\"\"\n",
    "    Given previously identified number of angles, vocabulary poses for hand techniques, and vocabulary poses for kicking techniques,\n",
    "    this method takes all vocabulary poses for each move from a `path_to_ks` pickle file, which contains a dictionary that maps prefix to vocab poses, and generates\n",
    "    a random identifier for each of the 20 possibilities (randomly chosen, to avoid any mixup with similar moves being assigned close numbers), and generates and saves the X,y arrays for KNN training\n",
    "    :param path_to_ks: the path to the ks pickle file\n",
    "    :param suffix: the identifier for a specific number of vocabulary poses, ex. h10k12 means 10 vocab poses for hand techniques and 12 vocab poses for kicking techniques\n",
    "    :param new_identifiers: whether or not to create new identifiers, or use the existing pickle file (defaults to false)\n",
    "    :return: X (the angles representations of the vocabulary poses), y (the identifier of the prefix the corresponding vocab pose belongs to), the dictionary that maps the random int indentifier to the prefix, and the dictionary that maps the prefix to the identifier\n",
    "    \"\"\"\n",
    "\n",
    "    ks = pickle.load(open(path_to_ks, 'rb'))\n",
    "\n",
    "    num_angles = 14\n",
    "    total_poses = (hand_vp * 2 * len(hand_techniques)) + (kick_vp * 2 * len(kicking_techniques))\n",
    "\n",
    "    X = np.empty((total_poses, num_angles))\n",
    "    y = np.array([])\n",
    "\n",
    "    if new_identifiers == True:\n",
    "        identifier2move = {}\n",
    "        move2identifier = {}\n",
    "        identifiers = [i for i in range(len(ks.values()))]\n",
    "        random.shuffle(identifiers)\n",
    "    else:\n",
    "        identifier2move, move2identifier = pickle.load(open(os.path.join(lu, f'moveids.p'), 'rb'))\n",
    "\n",
    "    count = 0\n",
    "    for move in ks:\n",
    "        if new_identifiers == True:\n",
    "            moveid = identifiers.pop()\n",
    "            identifier2move[moveid] = move\n",
    "            move2identifier[move] = moveid\n",
    "        else:\n",
    "            moveid = move2identifier[move]\n",
    "        vocab_poses = ks[move].cluster_centers_\n",
    "        for pose in vocab_poses:\n",
    "            X[count] = pose #where X is the collection of vocab poses that map\n",
    "            y = np.append(y, [moveid])\n",
    "            count += 1\n",
    "    np.savez(os.path.join(lu, suffix), X, y)\n",
    "    if new_identifiers == True:\n",
    "        pickle.dump((identifier2move, move2identifier), open(os.path.join(lu, f'moveids.p'), 'wb'))\n",
    "    return X,y, identifier2move, move2identifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fg2KI702H-4Q"
   },
   "source": [
    "def classify_videos(ips, tech, ks_name, new_ids=False):\n",
    "    \"\"\"\n",
    "    Classifies all videos in `ips` according to whether its a hand or foot technique and to the kmeans objects containing vocabulary poses into one of the 20 possibilities (10 moves, each side)\n",
    "    :param ips: list of strings for the names of all .npy files that should be classified into a technique\n",
    "    :param tech: list of strings, either 'h' for hand technique or 'k' for kicking technique, that match up with the list of filenames in `ips` #obsolete in sample runs since we just assume its the technique which requires the largest number of vocabulary poses (so kicking techniques)\n",
    "    :param ks_name: the name of the pickle file where the kmeans objects from training are stored (containing the vocabulary poses for each of the 20 possibilities), ex. ks-h10k12.p\n",
    "    :param new_ids: boolean for whether or not new identifiers should be generated, assumed to already be stored in `moveids.p`\n",
    "    :return: an array of tuples, the first value is the string abbreviation for which move the given video has been classified into and a string for how many out of the total vocabulary poses led to that conclusion\n",
    "    \"\"\"\n",
    "    path_to_ks = os.path.join(lu, ks_name)\n",
    "    suffix = path_to_ks[path_to_ks.find('-')+1:path_to_ks.find('.p')]\n",
    "\n",
    "    if not os.path.exists(os.path.join(lu, f'{suffix}.npz')):\n",
    "        X, y, identifier2move, move2identifier = get_data(path_to_ks, suffix, new_identifiers=new_ids)\n",
    "    else:\n",
    "        npzfile = np.load(os.path.join(lu, f'{suffix}.npz'))\n",
    "        X,y = npzfile['arr_0'], npzfile['arr_1']\n",
    "        identifier2move, move2identifier = pickle.load(open(os.path.join(lu, f'moveids.p'), 'rb'))\n",
    "\n",
    "    # neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "    # neigh = KNeighborsClassifier(n_neighbors=12)\n",
    "    neigh.fit(X, y)\n",
    "\n",
    "    final_res = []\n",
    "    for i, ip in enumerate(ips):\n",
    "        if tech == None or tech[i] == 'k':\n",
    "          num_vp = int(suffix[suffix.find('k')+1:])\n",
    "        elif tech[i] == 'h':\n",
    "            num_vp = int(suffix[suffix.find('h')+1:suffix.find('k')])\n",
    "\n",
    "        sample_kmeans = get_cluster_centroids(num_vp, [ip])\n",
    "\n",
    "        res = []\n",
    "        for pose in sample_kmeans.cluster_centers_:\n",
    "            res.append(neigh.predict([pose]))\n",
    "\n",
    "        tally = {}\n",
    "        for r in res:\n",
    "            m = identifier2move[r[0]]\n",
    "            if m not in tally:\n",
    "                tally[m] = 1\n",
    "            else:\n",
    "                tally[m] += 1\n",
    "\n",
    "        # for w in sorted(tally, key=tally.get, reverse=True):\n",
    "        #     print(w, tally[w])\n",
    "            # final_res.append(tally.values())\n",
    "        maxvote_move = max(tally, key=tally.get)\n",
    "        final_res.append((maxvote_move, f'{tally[maxvote_move]}/{sum(tally.values())}'))\n",
    "    return final_res"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s-hi81eFT6C8"
   },
   "source": [
    "def pose_classification_helper(leadup, m, moves_type, dts_id, side, ks_name, pr, acc_writer, dl=False):\n",
    "    \"\"\"\n",
    "    Classifies test videos of a given move into one of the 20 possibilities\n",
    "    :param leadup: the path to the test videos\n",
    "    :param m: the move for which to download videos, ex. `High block`\n",
    "    :param moves_type: whether the given move is a hand or kicking technique, 'h' or 'k'\n",
    "    :param dts_id: a special identifier added to the end of directory name, ex. `test`\n",
    "    :param side: the side for which to download videos, ex. `Left`\n",
    "    :param ks_name: the name of where the pickle file storing kmeans objects containing the vocabulary poses is stored\n",
    "    :param pr: the list of (observed, expected) tuples to which the results of this move's classification results will be appended\n",
    "    :param acc_writer: the file writer which prints the bare-bones accuracy, misclassified/total\n",
    "    :param dl: if a download is necessary, defaults to false since oftentimes the videos have already been downloaded in the current runtime\n",
    "    :return: the prefix (one of the 20 possibilities) and the accuracy\n",
    "    \"\"\"\n",
    "    if dl == True:\n",
    "        prefix = download_all_videos(leadup, test_videos, side, m, False, dts_id)\n",
    "        oup_folder, dts = create_custom_dataset(leadup, f'{prefix}_{dts_id}', slow=False)\n",
    "        reconstruct_videos(leadup, f'{prefix}_{dts_id}', dts)\n",
    "    else:\n",
    "        prefix = f'{abbreviations[m]}_{side[0].lower()}'\n",
    "\n",
    "    ips = get_ips(leadup, f'{prefix}_{dts_id}')\n",
    "    tech = [moves_type] * len(ips)\n",
    "\n",
    "    res = classify_videos(ips, tech, ks_name)\n",
    "    for ip, fr in zip(ips, res):\n",
    "        print(f'{os.path.basename(ip)}\\t|\\t{fr[0]}\\t{fr[1]}')\n",
    "        acc_writer.write(f'{os.path.basename(ip)}\\t|\\t{fr[0]}\\t{fr[1]}\\n')\n",
    "\n",
    "    misclass = 0\n",
    "    for (elem, vote) in res:\n",
    "        if elem != prefix:\n",
    "            misclass += 1\n",
    "        pr.append((elem, prefix))\n",
    "    acc = 1 - (misclass / len(ips))\n",
    "    print(f'Accuracy: {acc}')\n",
    "    acc_writer.write(f'Accuracy: {acc}\\n')\n",
    "    return prefix, acc\n",
    "\n",
    "\n",
    "def pose_classification(leadup, moves, moves_type, dts_id, ks_name, pr, prefixes, version, dl=False):\n",
    "    \"\"\"\n",
    "    Classifies test videos of every move in `moves` into one of the 20 possibilities\n",
    "    :param leadup: the path to the test videos\n",
    "    :param moves: the list of all the moves (ex. ['High block', 'Low block']) for which classification is necessary\n",
    "    :param moves_type: whether the given move is a hand or kicking technique, 'h' or 'k'\n",
    "    :param dts_id: a special identifier added to the end of directory name, ex. `test`\n",
    "    :param ks_name: the name of where the pickle file storing kmeans objects containing the vocabulary poses is stored\n",
    "    :param pr: the list of (observed, expected) tuples to which the results of this move's classification results will be appended\n",
    "    :param prefixes: the list of all prefixes generated as a byproduct of this method in order to later calculate the f1 scores\n",
    "    :param version: a number to identify this specific combination of modifications (ex. different number of vocab poses)\n",
    "    :param dl: if a download is necessary, defaults to false since oftentimes the videos have already been downloaded in the current runtime\n",
    "    :return: the list of bare-boned accuracies\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    acc_writer = open(\n",
    "        os.path.join(lu, f\"pose_class_res_{ks_name[ks_name.find('-') + 1:ks_name.find('.')]}_v{version}.txt\"), \"a\")\n",
    "    for m in moves:\n",
    "        prefix, acc = pose_classification_helper(leadup, m, moves_type, dts_id, 'Left', ks_name, pr, acc_writer, dl=dl)\n",
    "        prefixes.append(prefix)\n",
    "        accuracies.append(acc)\n",
    "        prefix, acc = pose_classification_helper(leadup, m, moves_type, dts_id, 'Right', ks_name, pr, acc_writer, dl=dl)\n",
    "        prefixes.append(prefix)\n",
    "        accuracies.append(acc)\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(f'Average Accuracy: {avg_accuracy}')\n",
    "    acc_writer.write(f'Average Accuracy: {avg_accuracy}\\n\\n')\n",
    "    acc_writer.close()\n",
    "    return accuracies"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e6YUTiKrVrHr"
   },
   "source": [
    "def get_acc_metrics(prefix, pr, metrics_writer):  # searching in pr for this prefix\n",
    "    \"\"\"\n",
    "    Calculates and returns the F1 score for a given move with prefix given the predicted value and the result in pr\n",
    "    :param prefix: the move for which to calculate the f1 score\n",
    "    :param pr: an array of (predicted, result) values for all moves in the test set\n",
    "    :param metrics_writer: the file writer to print the metrics results\n",
    "    :return: the f1 score\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'{prefix}')\n",
    "    metrics_writer.write(f'{prefix}\\n')\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for pred, res in pr:\n",
    "        if pred == res == prefix:\n",
    "            tp += 1\n",
    "        elif pred == prefix and res != prefix:\n",
    "            fp += 1\n",
    "        elif pred != prefix and res != prefix:\n",
    "            tn += 1\n",
    "        elif pred != prefix and res == prefix:\n",
    "            fn += 1\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = float(\"nan\")\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = float(\"nan\")\n",
    "    print(f'Precision: {precision}')\n",
    "    metrics_writer.write(f'\\tPrecision: {precision}\\n')\n",
    "    print(f'Recall: {recall}')\n",
    "    metrics_writer.write(f'\\tRecall: {recall}\\n')\n",
    "    try:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    except:\n",
    "        f1 = float(\"nan\")\n",
    "    print(f'F1: {f1}')\n",
    "    metrics_writer.write(f'\\tF1: {f1}\\n\\n')\n",
    "    return f1\n",
    "\n",
    "def get_all_f1s(prefixes, pred_res, ks_name, version=0):\n",
    "    \"\"\"\n",
    "    Gets all the f1 scores for every prefix in `prefixes`\n",
    "    :param prefixes: the list of every prefix for which to calculate an f1 score\n",
    "    :param pred_res: the pr object that stores (observed, expected) tuples\n",
    "    :param ks_name: the name of the ks file, from which to get the naming convention to print the f1 results in a file\n",
    "    :param version: a number to identify this specific combination of modifications (ex. different number of vocab poses)\n",
    "    :return: a dictionary that maps prefix to f1 score\n",
    "    \"\"\"\n",
    "    f1_writer = open(os.path.join(lu, f\"res_{ks_name[ks_name.find('-') + 1:ks_name.find('.')]}_v{version}.txt\"), \"w\")\n",
    "    f1_score = {}\n",
    "    for p in prefixes:\n",
    "        f1_score[p] = get_acc_metrics(p, pred_res, f1_writer)\n",
    "    f1_writer.close()\n",
    "    return f1_score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IcP2YH1na-fR"
   },
   "source": [
    "# !cd \"$lu/TestSet\" && zip -q -r \"TestSet_NPYs&MP4s.zip\" ''"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DzLszWmla7_h"
   },
   "source": [
    "unzip_folder(os.path.join(lu, 'TestSet_NPYs&MP4s.zip'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y58VSUE8WiER"
   },
   "source": [
    "ks_name = f'ks-h{hand_vp}k{kick_vp}.p'\n",
    "pr = []\n",
    "prefixes = []\n",
    "pose_classification('TestSet', hand_techniques, 'h', 'test', ks_name, pr, prefixes, version=5, dl=False)\n",
    "pose_classification('TestSet', kicking_techniques, 'k', 'test', ks_name, pr, prefixes, version=5, dl=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGzc6Iki3L_2"
   },
   "source": [
    "# pickle.dump(pr, open('pr.p', 'wb'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ql8bNsWi1sWC"
   },
   "source": [
    "get_all_f1s(prefixes, pr, ks_name, version=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW3L_AfM0Wum"
   },
   "source": [
    "## Temporal Alignment (DTW)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JZDC4eFjO-0G"
   },
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VvpajCeRMhes"
   },
   "source": [
    "def get_ideal_videos(leadup, dts_id='ideal'):\n",
    "    \"\"\"\n",
    "    Downloads all the ideal videos\n",
    "    :param leadup: the path for where to output the ideal videos\n",
    "    :param dts_id: a special identifier added to the end of all files pertaining to the ideal videos (most specifically, the custom datasets), ex. `ideal`\n",
    "    \"\"\"\n",
    "\n",
    "    move2ideal = get_ideal_file_ids(df_full)\n",
    "    print(move2ideal)\n",
    "    dir = os.path.join(leadup, dts_id)\n",
    "    if not os.path.exists(dir):  # make the initial videos folder\n",
    "        os.makedirs(dir)\n",
    "    for prefix in move2ideal:\n",
    "        download_video_helper(move2ideal[prefix], dir, prefix, None, None, dts_id)\n",
    "    print(\"Downloaded all ideal videos\")\n",
    "    oup_folder, dts = create_custom_dataset(leadup, dts_id, slow=False)\n",
    "    reconstruct_videos(leadup, None, dts, dts_id)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bGexc7WPJzH4"
   },
   "source": [
    "# get_ideal_videos()\n",
    "unzip_folder(os.path.join(lu, 'IdealSet_NPYs&MP4s.zip'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XaCS0cRjW3kk"
   },
   "source": [
    "def dtw_compare_samples(ips, oup):\n",
    "    \"\"\"\n",
    "    Compares all the videos represented by .npy files in `ips` to the output `oup` using fastdtw\n",
    "    :param ips: the list of strings of the names of input .npy files\n",
    "    :param oup: the path to the ideal .npy file for this given move\n",
    "    :return: the distance (similarity) between the ip and oup\n",
    "    \"\"\"\n",
    "    d = []\n",
    "    y = get_angles(np.load(oup))\n",
    "    for i in ips:\n",
    "        X = get_angles(np.load(i))\n",
    "        distance, path = fastdtw(X, y, dist=euclidean)\n",
    "        d.append(distance)\n",
    "    return d\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-0dBXZsSOcKS"
   },
   "source": [
    "# prefix = 'hb_l'\n",
    "# ips = get_ips('TestSet', f'{prefix}_test')\n",
    "# oup = os.path.join('ideal_3d_outputs', f'{prefix}_ideal_si.npy')\n",
    "# dtw_compare_samples(ips, oup)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t-VCkhVCUZEJ"
   },
   "source": [
    "#To test whether just skipping the pose classification module and just directly comparing video to all ideals (best score is what this move is considered to be) is better; it's not\n",
    "\n",
    "def dtw_testing_helper(leadup, prefixes, ip):\n",
    "    maxs = {}\n",
    "    for prefix in prefixes:\n",
    "        oup = os.path.join(leadup, f'{prefix}_ideal_si.npy')\n",
    "        maxs[prefix] = dtw_compare_samples(ip, oup)\n",
    "    maxvote_move = min(maxs, key=maxs.get)\n",
    "    print(maxvote_move)\n",
    "    return maxvote_move\n",
    "\n",
    "\n",
    "def dtw_testing(leadup, prefixes, pr_dtw):\n",
    "    for prefix in prefixes:\n",
    "        ips = get_ips('TestSet', f'{prefix}_test')\n",
    "        for ip in ips:\n",
    "            res = dtw_testing_helper(leadup, prefixes, [ip])\n",
    "            pr_dtw.append((prefix, res))\n",
    "\n",
    "pr_dtw = []\n",
    "dtw_testing('ideal_3d_outputs', prefixes, pr_dtw)\n",
    "get_all_f1s(prefixes, pr_dtw, ks_name, version=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjj5c1L0y3e_"
   },
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_o5mle3sf3fd"
   },
   "source": [
    "!chmod u+x \"$lu\"/convert2mp4.sh"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mwdDr2fNdoou"
   },
   "source": [
    "def convert2mp4(base):\n",
    "  !cd \"$base\" && ./../\"$lu\"/convert2mp4.sh"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7WWHp4vrfWTd"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "def evaluate_video():\n",
    "    \"\"\"\n",
    "    Given the name of a video,\n",
    "    1) ensures its in the necesssary directories and that it's a .mp4 file\n",
    "    2) Creates a custom dataset\n",
    "    3) Reconstructs the video\n",
    "    4) Classifies the video\n",
    "    5) Temporally aligns with DTW\n",
    "    6) Prints the results\n",
    "    \"\"\"\n",
    "    file = input('Enter the name of your video (ex. i/am/a/boss/test.mp4): ')  # assume in directory\n",
    "    lu_pipe, tail = os.path.split(file)\n",
    "    vidfn, ext = os.path.splitext(tail)\n",
    "\n",
    "    if ext != \".mp4\":\n",
    "        convert2mp4(lu_pipe)\n",
    "\n",
    "    ip_f_path = os.path.join(lu_pipe, vidfn)\n",
    "    if not os.path.exists(ip_f_path):\n",
    "        os.makedirs(ip_f_path)\n",
    "    !mv\n",
    "    \"$file\" \"$ip_f_path\"\n",
    "\n",
    "    oup_f, dts = create_custom_dataset(lu_pipe, vidfn, slow=False)\n",
    "    threed_outputs_folder_path = reconstruct_videos(lu_pipe, None, dts, oup_f)\n",
    "    show_local_mp4_video(f'{threed_outputs_folder_path}/{vidfn}_si.mp4')\n",
    "    ips = get_ips(lu_pipe, oup_f)\n",
    "    res = classify_videos(ips, None, ks_name)\n",
    "    move = res[0][0]\n",
    "    confidence = res[0][1]\n",
    "    confidence = int(confidence[:confidence.find('/')]) / int(confidence[confidence.find('/') + 1:])\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    print(f\"Your video was classified as a {move} with {confidence * 100}% confidence\")\n",
    "    oup = os.path.join('ideal_3d_outputs', f'{move}_ideal_si.npy')\n",
    "    d = dtw_compare_samples(ips, oup)\n",
    "    print(f\"Relative to the exemplar, your score is {d}. The closer to 0, the better your execution. Try again to get closer to 0.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "94stPmRbmxtf"
   },
   "source": [
    "evaluate_video()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}